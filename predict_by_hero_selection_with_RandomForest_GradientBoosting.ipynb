{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About\n",
    "\n",
    "This is the notebook for building PredictionByHero model using random forest (RF) and gradient boosting (GB). We will also look at PCA to see if reduction in dimension could help us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tim\\Anaconda3\\envs\\lol-predict\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and randomise data\n",
    "dataset = pd.read_csv('heroSelect.csv', index_col = 0)\n",
    "dataset = dataset.take(np.random.permutation(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset (173365, 273)\n"
     ]
    }
   ],
   "source": [
    "print('dataset', dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LR and MN\n",
    "Let's see how simple logistic regression and multinomial perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy: 0.529270608683\n",
      "MultinominalNB accuracy: 0.528111211201\n"
     ]
    }
   ],
   "source": [
    "x = dataset.drop('team1Win', axis=1)\n",
    "y = dataset['team1Win']\n",
    "\n",
    "#print results\n",
    "print('Logistic Regression accuracy:', np.mean(cross_val_score(LogisticRegression(), x, y, scoring='accuracy', cv=2)))\n",
    "print('MultinominalNB accuracy:', np.mean(cross_val_score(MultinomialNB(), x, y, scoring='accuracy', cv=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFmodel(train_x, train_y, test_x, test_y):\n",
    "    model = RandomForestClassifier(min_samples_split=15,\n",
    "                               min_samples_leaf=15,\n",
    "                               criterion=\"gini\",\n",
    "                               n_estimators=200,\n",
    "                               random_state=189,\n",
    "                               max_features=\"auto\")\n",
    "\n",
    "    print(\"Training model.\")\n",
    "    #train model\n",
    "    model.fit(train_x, train_y)\n",
    "    predicted_labels = model.predict(test_x) \n",
    "    print(\"FINISHED classifying. accuracy score : \")\n",
    "    print(accuracy_score(test_y, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GBmodel(train_x, train_y, test_x, test_y):\n",
    "    model = GradientBoostingClassifier(min_samples_split=15,\n",
    "                               min_samples_leaf=15,\n",
    "                               max_features='sqrt',\n",
    "                               n_estimators=200,\n",
    "                               random_state=189,\n",
    "                               subsample=0.8)\n",
    "\n",
    "    print(\"Training model.\")\n",
    "    #train model\n",
    "    model.fit(train_x, train_y)\n",
    "    predicted_labels = model.predict(test_x) \n",
    "    print(\"FINISHED classifying. accuracy score : \")\n",
    "    print(accuracy_score(test_y, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the model without principal component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_feed_RF(dataset):\n",
    "    team_data = dataset.iloc[:,1:273]\n",
    "    winners = pd.get_dummies(dataset['team1Win'])\n",
    "    return team_data, winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_feed_GB(dataset):\n",
    "    team_data = dataset.iloc[:,1:273]\n",
    "    winners = dataset['team1Win']\n",
    "    return team_data, winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset, test_size = 0.1)\n",
    "trainX_RF, trainY_RF = get_data_feed_RF(train)\n",
    "testX_RF, testY_RF = get_data_feed_RF(test)\n",
    "trainX_GB, trainY_GB = get_data_feed_GB(train)\n",
    "testX_GB, testY_GB = get_data_feed_GB(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "FINISHED classifying. accuracy score : \n",
      "0.527369210359\n"
     ]
    }
   ],
   "source": [
    "RFmodel(trainX_RF, trainY_RF, testX_RF, testY_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "FINISHED classifying. accuracy score : \n",
      "0.532272019381\n"
     ]
    }
   ],
   "source": [
    "GBmodel(trainX_GB, trainY_GB, testX_GB, testY_GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Principal Component Analysis on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating out the features\n",
    "x = dataset.iloc[:,1:273].values\n",
    "# Separating out the target\n",
    "y = dataset.iloc[:,0:1]\n",
    "\n",
    "# Standardizing the features\n",
    "x = StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "      <th>267</th>\n",
       "      <th>268</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.199846</td>\n",
       "      <td>-0.252918</td>\n",
       "      <td>-0.130888</td>\n",
       "      <td>-0.326827</td>\n",
       "      <td>2.368155</td>\n",
       "      <td>-0.352802</td>\n",
       "      <td>-0.366285</td>\n",
       "      <td>-0.118332</td>\n",
       "      <td>-0.23818</td>\n",
       "      <td>-0.278275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125234</td>\n",
       "      <td>-0.197619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.163001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.199846</td>\n",
       "      <td>-0.252918</td>\n",
       "      <td>-0.130888</td>\n",
       "      <td>3.059723</td>\n",
       "      <td>-0.422270</td>\n",
       "      <td>-0.352802</td>\n",
       "      <td>-0.366285</td>\n",
       "      <td>-0.118332</td>\n",
       "      <td>-0.23818</td>\n",
       "      <td>-0.278275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125234</td>\n",
       "      <td>-0.197619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.163001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.199846</td>\n",
       "      <td>-0.252918</td>\n",
       "      <td>-0.130888</td>\n",
       "      <td>3.059723</td>\n",
       "      <td>-0.422270</td>\n",
       "      <td>-0.352802</td>\n",
       "      <td>2.730115</td>\n",
       "      <td>-0.118332</td>\n",
       "      <td>-0.23818</td>\n",
       "      <td>3.593567</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125234</td>\n",
       "      <td>-0.197619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.163001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.199846</td>\n",
       "      <td>-0.252918</td>\n",
       "      <td>-0.130888</td>\n",
       "      <td>-0.326827</td>\n",
       "      <td>-0.422270</td>\n",
       "      <td>-0.352802</td>\n",
       "      <td>-0.366285</td>\n",
       "      <td>-0.118332</td>\n",
       "      <td>-0.23818</td>\n",
       "      <td>-0.278275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125234</td>\n",
       "      <td>-0.197619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.163001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.199846</td>\n",
       "      <td>-0.252918</td>\n",
       "      <td>-0.130888</td>\n",
       "      <td>-0.326827</td>\n",
       "      <td>-0.422270</td>\n",
       "      <td>-0.352802</td>\n",
       "      <td>-0.366285</td>\n",
       "      <td>-0.118332</td>\n",
       "      <td>-0.23818</td>\n",
       "      <td>-0.278275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125234</td>\n",
       "      <td>-0.197619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.163001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.199846</td>\n",
       "      <td>3.953850</td>\n",
       "      <td>-0.130888</td>\n",
       "      <td>-0.326827</td>\n",
       "      <td>-0.422270</td>\n",
       "      <td>-0.352802</td>\n",
       "      <td>-0.366285</td>\n",
       "      <td>-0.118332</td>\n",
       "      <td>-0.23818</td>\n",
       "      <td>-0.278275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125234</td>\n",
       "      <td>-0.197619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.163001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.199846</td>\n",
       "      <td>-0.252918</td>\n",
       "      <td>-0.130888</td>\n",
       "      <td>-0.326827</td>\n",
       "      <td>-0.422270</td>\n",
       "      <td>-0.352802</td>\n",
       "      <td>-0.366285</td>\n",
       "      <td>-0.118332</td>\n",
       "      <td>-0.23818</td>\n",
       "      <td>-0.278275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125234</td>\n",
       "      <td>-0.197619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.163001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.199846</td>\n",
       "      <td>-0.252918</td>\n",
       "      <td>-0.130888</td>\n",
       "      <td>-0.326827</td>\n",
       "      <td>-0.422270</td>\n",
       "      <td>-0.352802</td>\n",
       "      <td>-0.366285</td>\n",
       "      <td>-0.118332</td>\n",
       "      <td>-0.23818</td>\n",
       "      <td>-0.278275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125234</td>\n",
       "      <td>-0.197619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.163001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.199846</td>\n",
       "      <td>-0.252918</td>\n",
       "      <td>-0.130888</td>\n",
       "      <td>-0.326827</td>\n",
       "      <td>-0.422270</td>\n",
       "      <td>-0.352802</td>\n",
       "      <td>-0.366285</td>\n",
       "      <td>-0.118332</td>\n",
       "      <td>-0.23818</td>\n",
       "      <td>-0.278275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125234</td>\n",
       "      <td>-0.197619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.163001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.199846</td>\n",
       "      <td>-0.252918</td>\n",
       "      <td>-0.130888</td>\n",
       "      <td>-0.326827</td>\n",
       "      <td>-0.422270</td>\n",
       "      <td>-0.352802</td>\n",
       "      <td>-0.366285</td>\n",
       "      <td>-0.118332</td>\n",
       "      <td>-0.23818</td>\n",
       "      <td>-0.278275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125234</td>\n",
       "      <td>-0.197619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.163001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.199846 -0.252918 -0.130888 -0.326827  2.368155 -0.352802 -0.366285   \n",
       "1 -0.199846 -0.252918 -0.130888  3.059723 -0.422270 -0.352802 -0.366285   \n",
       "2 -0.199846 -0.252918 -0.130888  3.059723 -0.422270 -0.352802  2.730115   \n",
       "3 -0.199846 -0.252918 -0.130888 -0.326827 -0.422270 -0.352802 -0.366285   \n",
       "4 -0.199846 -0.252918 -0.130888 -0.326827 -0.422270 -0.352802 -0.366285   \n",
       "5 -0.199846  3.953850 -0.130888 -0.326827 -0.422270 -0.352802 -0.366285   \n",
       "6 -0.199846 -0.252918 -0.130888 -0.326827 -0.422270 -0.352802 -0.366285   \n",
       "7 -0.199846 -0.252918 -0.130888 -0.326827 -0.422270 -0.352802 -0.366285   \n",
       "8 -0.199846 -0.252918 -0.130888 -0.326827 -0.422270 -0.352802 -0.366285   \n",
       "9 -0.199846 -0.252918 -0.130888 -0.326827 -0.422270 -0.352802 -0.366285   \n",
       "\n",
       "        7        8         9   ...        262       263  264  265  266  267  \\\n",
       "0 -0.118332 -0.23818 -0.278275 ...  -0.125234 -0.197619  0.0  0.0  0.0  0.0   \n",
       "1 -0.118332 -0.23818 -0.278275 ...  -0.125234 -0.197619  0.0  0.0  0.0  0.0   \n",
       "2 -0.118332 -0.23818  3.593567 ...  -0.125234 -0.197619  0.0  0.0  0.0  0.0   \n",
       "3 -0.118332 -0.23818 -0.278275 ...  -0.125234 -0.197619  0.0  0.0  0.0  0.0   \n",
       "4 -0.118332 -0.23818 -0.278275 ...  -0.125234 -0.197619  0.0  0.0  0.0  0.0   \n",
       "5 -0.118332 -0.23818 -0.278275 ...  -0.125234 -0.197619  0.0  0.0  0.0  0.0   \n",
       "6 -0.118332 -0.23818 -0.278275 ...  -0.125234 -0.197619  0.0  0.0  0.0  0.0   \n",
       "7 -0.118332 -0.23818 -0.278275 ...  -0.125234 -0.197619  0.0  0.0  0.0  0.0   \n",
       "8 -0.118332 -0.23818 -0.278275 ...  -0.125234 -0.197619  0.0  0.0  0.0  0.0   \n",
       "9 -0.118332 -0.23818 -0.278275 ...  -0.125234 -0.197619  0.0  0.0  0.0  0.0   \n",
       "\n",
       "        268  269  270  271  \n",
       "0 -0.163001  0.0  0.0  0.0  \n",
       "1 -0.163001  0.0  0.0  0.0  \n",
       "2 -0.163001  0.0  0.0  0.0  \n",
       "3 -0.163001  0.0  0.0  0.0  \n",
       "4 -0.163001  0.0  0.0  0.0  \n",
       "5 -0.163001  0.0  0.0  0.0  \n",
       "6 -0.163001  0.0  0.0  0.0  \n",
       "7 -0.163001  0.0  0.0  0.0  \n",
       "8 -0.163001  0.0  0.0  0.0  \n",
       "9 -0.163001  0.0  0.0  0.0  \n",
       "\n",
       "[10 rows x 272 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = x).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>team1Win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.695495</td>\n",
       "      <td>0.588624</td>\n",
       "      <td>0.053370</td>\n",
       "      <td>0.262934</td>\n",
       "      <td>0.207734</td>\n",
       "      <td>-1.068153</td>\n",
       "      <td>-0.371155</td>\n",
       "      <td>-0.327290</td>\n",
       "      <td>1.109409</td>\n",
       "      <td>-1.348514</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.783698</td>\n",
       "      <td>-0.507744</td>\n",
       "      <td>-0.365657</td>\n",
       "      <td>0.279444</td>\n",
       "      <td>-0.326010</td>\n",
       "      <td>0.881307</td>\n",
       "      <td>1.925227</td>\n",
       "      <td>-0.020426</td>\n",
       "      <td>0.544384</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.106369</td>\n",
       "      <td>-1.296062</td>\n",
       "      <td>-0.506209</td>\n",
       "      <td>0.999421</td>\n",
       "      <td>-1.721088</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.048172</td>\n",
       "      <td>0.615494</td>\n",
       "      <td>0.809916</td>\n",
       "      <td>-0.214167</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.743328</td>\n",
       "      <td>-0.234031</td>\n",
       "      <td>1.755046</td>\n",
       "      <td>-0.360779</td>\n",
       "      <td>3.469277</td>\n",
       "      <td>1.410107</td>\n",
       "      <td>-0.282242</td>\n",
       "      <td>0.067796</td>\n",
       "      <td>-2.562912</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.604015</td>\n",
       "      <td>-0.057264</td>\n",
       "      <td>-0.418116</td>\n",
       "      <td>1.761370</td>\n",
       "      <td>-0.988363</td>\n",
       "      <td>1.413017</td>\n",
       "      <td>-1.482368</td>\n",
       "      <td>1.672793</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>-0.832969</td>\n",
       "      <td>...</td>\n",
       "      <td>1.667768</td>\n",
       "      <td>0.894235</td>\n",
       "      <td>-0.772172</td>\n",
       "      <td>0.221010</td>\n",
       "      <td>-0.376656</td>\n",
       "      <td>0.453750</td>\n",
       "      <td>3.242296</td>\n",
       "      <td>3.097436</td>\n",
       "      <td>1.840584</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.232472</td>\n",
       "      <td>-0.161850</td>\n",
       "      <td>0.107759</td>\n",
       "      <td>0.513880</td>\n",
       "      <td>-0.432835</td>\n",
       "      <td>-0.279387</td>\n",
       "      <td>-0.070221</td>\n",
       "      <td>-1.225025</td>\n",
       "      <td>-0.282572</td>\n",
       "      <td>2.445482</td>\n",
       "      <td>...</td>\n",
       "      <td>1.833812</td>\n",
       "      <td>-0.704022</td>\n",
       "      <td>-0.389914</td>\n",
       "      <td>-0.816592</td>\n",
       "      <td>0.208050</td>\n",
       "      <td>-0.294238</td>\n",
       "      <td>0.310845</td>\n",
       "      <td>-1.101396</td>\n",
       "      <td>-0.426887</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.797457</td>\n",
       "      <td>-0.365956</td>\n",
       "      <td>-1.521082</td>\n",
       "      <td>0.415012</td>\n",
       "      <td>-0.278537</td>\n",
       "      <td>-0.520815</td>\n",
       "      <td>-0.410934</td>\n",
       "      <td>1.925119</td>\n",
       "      <td>1.180003</td>\n",
       "      <td>0.498312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036346</td>\n",
       "      <td>-0.644029</td>\n",
       "      <td>0.283569</td>\n",
       "      <td>-1.686825</td>\n",
       "      <td>-0.842367</td>\n",
       "      <td>0.048724</td>\n",
       "      <td>0.738326</td>\n",
       "      <td>1.120965</td>\n",
       "      <td>1.158546</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.459209</td>\n",
       "      <td>0.426411</td>\n",
       "      <td>-0.469873</td>\n",
       "      <td>0.131485</td>\n",
       "      <td>-1.425457</td>\n",
       "      <td>-1.156990</td>\n",
       "      <td>-1.391055</td>\n",
       "      <td>0.773985</td>\n",
       "      <td>1.895068</td>\n",
       "      <td>-0.789987</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.163933</td>\n",
       "      <td>0.091501</td>\n",
       "      <td>-0.581819</td>\n",
       "      <td>-0.865447</td>\n",
       "      <td>-1.494994</td>\n",
       "      <td>-0.097117</td>\n",
       "      <td>1.048388</td>\n",
       "      <td>0.098692</td>\n",
       "      <td>-0.468137</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.834276</td>\n",
       "      <td>0.045706</td>\n",
       "      <td>-0.071843</td>\n",
       "      <td>1.634345</td>\n",
       "      <td>0.985174</td>\n",
       "      <td>-1.309315</td>\n",
       "      <td>-0.602668</td>\n",
       "      <td>-0.744599</td>\n",
       "      <td>-0.906137</td>\n",
       "      <td>-0.081359</td>\n",
       "      <td>...</td>\n",
       "      <td>2.242615</td>\n",
       "      <td>-1.699425</td>\n",
       "      <td>-1.729580</td>\n",
       "      <td>-0.154835</td>\n",
       "      <td>-0.793104</td>\n",
       "      <td>-2.541849</td>\n",
       "      <td>-0.963479</td>\n",
       "      <td>1.440992</td>\n",
       "      <td>0.571478</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.385556</td>\n",
       "      <td>-0.478857</td>\n",
       "      <td>0.109226</td>\n",
       "      <td>-0.130996</td>\n",
       "      <td>-1.033345</td>\n",
       "      <td>-0.561888</td>\n",
       "      <td>-0.497096</td>\n",
       "      <td>0.629695</td>\n",
       "      <td>-0.938655</td>\n",
       "      <td>0.739291</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.242070</td>\n",
       "      <td>1.617481</td>\n",
       "      <td>-0.157324</td>\n",
       "      <td>0.100960</td>\n",
       "      <td>1.243656</td>\n",
       "      <td>-0.312762</td>\n",
       "      <td>-1.516538</td>\n",
       "      <td>-1.617369</td>\n",
       "      <td>-0.243068</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003463</td>\n",
       "      <td>-0.329272</td>\n",
       "      <td>0.384721</td>\n",
       "      <td>-0.240837</td>\n",
       "      <td>-1.392502</td>\n",
       "      <td>-0.492360</td>\n",
       "      <td>0.696097</td>\n",
       "      <td>-0.055994</td>\n",
       "      <td>-1.961645</td>\n",
       "      <td>-1.090175</td>\n",
       "      <td>...</td>\n",
       "      <td>1.076950</td>\n",
       "      <td>1.411304</td>\n",
       "      <td>-1.459586</td>\n",
       "      <td>2.021538</td>\n",
       "      <td>-0.688621</td>\n",
       "      <td>-1.362194</td>\n",
       "      <td>0.497146</td>\n",
       "      <td>-3.707704</td>\n",
       "      <td>0.094551</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-2.520273</td>\n",
       "      <td>-2.459542</td>\n",
       "      <td>0.413584</td>\n",
       "      <td>0.113831</td>\n",
       "      <td>-0.452076</td>\n",
       "      <td>-0.658358</td>\n",
       "      <td>0.122794</td>\n",
       "      <td>0.474335</td>\n",
       "      <td>-0.933415</td>\n",
       "      <td>0.278085</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.288216</td>\n",
       "      <td>0.604381</td>\n",
       "      <td>-0.390425</td>\n",
       "      <td>-0.044636</td>\n",
       "      <td>0.068274</td>\n",
       "      <td>-0.000998</td>\n",
       "      <td>1.160504</td>\n",
       "      <td>-0.594690</td>\n",
       "      <td>0.974285</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.695495  0.588624  0.053370  0.262934  0.207734 -1.068153 -0.371155   \n",
       "1 -0.106369 -1.296062 -0.506209  0.999421 -1.721088  0.450704  0.048172   \n",
       "2  1.604015 -0.057264 -0.418116  1.761370 -0.988363  1.413017 -1.482368   \n",
       "3 -0.232472 -0.161850  0.107759  0.513880 -0.432835 -0.279387 -0.070221   \n",
       "4 -1.797457 -0.365956 -1.521082  0.415012 -0.278537 -0.520815 -0.410934   \n",
       "5 -0.459209  0.426411 -0.469873  0.131485 -1.425457 -1.156990 -1.391055   \n",
       "6  0.834276  0.045706 -0.071843  1.634345  0.985174 -1.309315 -0.602668   \n",
       "7  1.385556 -0.478857  0.109226 -0.130996 -1.033345 -0.561888 -0.497096   \n",
       "8  0.003463 -0.329272  0.384721 -0.240837 -1.392502 -0.492360  0.696097   \n",
       "9 -2.520273 -2.459542  0.413584  0.113831 -0.452076 -0.658358  0.122794   \n",
       "\n",
       "          7         8         9    ...          127       128       129  \\\n",
       "0 -0.327290  1.109409 -1.348514    ...    -0.783698 -0.507744 -0.365657   \n",
       "1  0.615494  0.809916 -0.214167    ...    -0.743328 -0.234031  1.755046   \n",
       "2  1.672793  0.611771 -0.832969    ...     1.667768  0.894235 -0.772172   \n",
       "3 -1.225025 -0.282572  2.445482    ...     1.833812 -0.704022 -0.389914   \n",
       "4  1.925119  1.180003  0.498312    ...     0.036346 -0.644029  0.283569   \n",
       "5  0.773985  1.895068 -0.789987    ...    -1.163933  0.091501 -0.581819   \n",
       "6 -0.744599 -0.906137 -0.081359    ...     2.242615 -1.699425 -1.729580   \n",
       "7  0.629695 -0.938655  0.739291    ...    -0.242070  1.617481 -0.157324   \n",
       "8 -0.055994 -1.961645 -1.090175    ...     1.076950  1.411304 -1.459586   \n",
       "9  0.474335 -0.933415  0.278085    ...    -1.288216  0.604381 -0.390425   \n",
       "\n",
       "        130       131       132       133       134       135  team1Win  \n",
       "0  0.279444 -0.326010  0.881307  1.925227 -0.020426  0.544384      -1.0  \n",
       "1 -0.360779  3.469277  1.410107 -0.282242  0.067796 -2.562912      -1.0  \n",
       "2  0.221010 -0.376656  0.453750  3.242296  3.097436  1.840584      -1.0  \n",
       "3 -0.816592  0.208050 -0.294238  0.310845 -1.101396 -0.426887      -1.0  \n",
       "4 -1.686825 -0.842367  0.048724  0.738326  1.120965  1.158546      -1.0  \n",
       "5 -0.865447 -1.494994 -0.097117  1.048388  0.098692 -0.468137       1.0  \n",
       "6 -0.154835 -0.793104 -2.541849 -0.963479  1.440992  0.571478      -1.0  \n",
       "7  0.100960  1.243656 -0.312762 -1.516538 -1.617369 -0.243068      -1.0  \n",
       "8  2.021538 -0.688621 -1.362194  0.497146 -3.707704  0.094551      -1.0  \n",
       "9 -0.044636  0.068274 -0.000998  1.160504 -0.594690  0.974285       1.0  \n",
       "\n",
       "[10 rows x 137 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=136, whiten=True) #reduce dimension by half\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents)\n",
    "finalDf = pd.concat([principalDf, y], axis=1)\n",
    "finalDf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(finalDf, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PCA_data_feed_RF(dataset):\n",
    "    team_data = dataset.iloc[:,0:135]\n",
    "    winners = pd.get_dummies(dataset['team1Win'])\n",
    "    return team_data, winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PCA_data_feed_GB(dataset):\n",
    "    team_data = dataset.iloc[:,0:135]\n",
    "    winners = dataset['team1Win']\n",
    "    return team_data, winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_RF, trainY_RF = get_PCA_data_feed_RF(train)\n",
    "testX_RF, testY_RF = get_PCA_data_feed_RF(test)\n",
    "trainX_GB, trainY_GB = get_PCA_data_feed_GB(train)\n",
    "testX_GB, testY_GB = get_PCA_data_feed_GB(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "FINISHED classifying. accuracy score : \n",
      "0.500490280902\n"
     ]
    }
   ],
   "source": [
    "RFmodel(trainX_RF, trainY_RF, testX_RF, testY_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "FINISHED classifying. accuracy score : \n",
      "0.505335409817\n"
     ]
    }
   ],
   "source": [
    "GBmodel(trainX_GB, trainY_GB, testX_GB, testY_GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We can see PCA, in fact, worsen the performance of our models by information loss during dimension reduction.\n",
    "\n",
    "Also bear in mind that our baseline percentage is 54%.\n",
    "\n",
    "And by only looking at hero selections, Gradient Boosting Classifier(GB) has the best accuracy (53.2%) but still not enough to pass our baseline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
