{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About\n",
    "\n",
    "This is the notebook for building PredictionByHero model using neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tim12\\AppData\\Local\\conda\\conda\\envs\\tensorflow_cpu\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and randomise data\n",
    "dataset = pd.read_csv('heroSelect.csv', index_col = 0)\n",
    "dataset = dataset.take(np.random.permutation(len(dataset)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to know how well our neural network is when compared with LR and MNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy: 0.528290017201323\n",
      "MultinominalNB accuracy: 0.5285380498423687\n"
     ]
    }
   ],
   "source": [
    "x = dataset.drop('team1Win', axis=1)\n",
    "y = dataset['team1Win']\n",
    "\n",
    "#print results\n",
    "print('Logistic Regression accuracy:', np.mean(cross_val_score(LogisticRegression(), x, y, scoring='accuracy', cv=2)))\n",
    "print('MultinominalNB accuracy:', np.mean(cross_val_score(MultinomialNB(), x, y, scoring='accuracy', cv=2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us percentages of matches are won by team 1. If we blindly choose team 1 to be the winner for all matches, this tells us the \"accuracy\" for this non-sense method and serves as the baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88670\n",
      "0.516658308440355\n"
     ]
    }
   ],
   "source": [
    "t1win = 0\n",
    "for idx, x in dataset['team1Win'].iteritems():\n",
    "    if(x==1.0):\n",
    "        t1win+=1\n",
    "print(t1win)\n",
    "print((183452-t1win)/183452)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset (173365, 273)\n",
      "train: (140425, 273) validation: (17337, 273) test: (15603, 273)\n"
     ]
    }
   ],
   "source": [
    "print('dataset', dataset.shape)\n",
    "dataset, validation = train_test_split(dataset, test_size = 0.1)\n",
    "train, test = train_test_split(dataset, test_size = 0.1)\n",
    "print('train:', train.shape, 'validation:', validation.shape, 'test:', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input/output placeholders\n",
    "x_team1    = tf.placeholder(\"float\", shape=[None, 136], name='x_team1')\n",
    "x_team2 = tf.placeholder(\"float\", shape=[None, 136], name='x_team1')\n",
    "y_true = tf.placeholder(\"float\", shape=[None, 2], name='y_true')\n",
    "\n",
    "#we'll use dropout layers for regularisation which need a keep probability\n",
    "keep_prob1 = tf.placeholder(\"float\", name='keep_prob1')\n",
    "keep_prob2 = tf.placeholder(\"float\", name='keep_prob2')\n",
    "\n",
    "#there doesn't seem to be any other way to differenciate train and validation summaries for TensorBoard\n",
    "loss_name     = tf.placeholder(\"string\", name='loss_name')\n",
    "accuracy_name = tf.placeholder(\"string\", name='accuracy_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight init for fully connected layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc_weight_bias(in_size, out_size):\n",
    "    initial_weight = tf.truncated_normal([in_size, out_size], stddev=0.2, mean=0.0)\n",
    "    initial_bias = tf.constant(0.1, shape=[out_size])\n",
    "    return tf.Variable(initial_weight), tf.Variable(initial_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"hero_layers_1\") as scope:\n",
    "    W_hero1, b_hero1 = fc_weight_bias(136,100)      \n",
    "    #note that team1 layer and team2 layer use the same weights and biases\n",
    "    team1_layer1 = tf.nn.relu(tf.matmul(x_team1, W_hero1) + b_hero1)\n",
    "    team2_layer1 = tf.nn.relu(tf.matmul(x_team2, W_hero1) + b_hero1)\n",
    "\n",
    "#second hero layer\n",
    "with tf.name_scope(\"hero_layers_2\") as scope:    \n",
    "    W_hero2, b_hero2 = fc_weight_bias(100,100)    \n",
    "    #again, team1 and team2 use the same weights and biases\n",
    "    team1_layer2 = tf.nn.relu(tf.matmul(team1_layer1, W_hero2) + b_hero2)\n",
    "    team2_layer2 = tf.nn.relu(tf.matmul(team2_layer1, W_hero2) + b_hero2)\n",
    "\n",
    "#now concatenate the team1 and team2 team outputs\n",
    "with tf.name_scope(\"hero_layers_concat\") as scope:\n",
    "    team1_team2_concat = tf.concat([team1_layer2, team2_layer2], 1)\n",
    "    team1_team2_drop = tf.nn.dropout(team1_team2_concat, keep_prob1)\n",
    "    h_drop1 = tf.nn.dropout(team1_team2_drop, keep_prob1)\n",
    "\n",
    "with tf.name_scope(\"hidden_layer_1\") as scope:\n",
    "    W_hidden1, b_hidden1 = fc_weight_bias(200,130)    \n",
    "    h_hidden1 = tf.nn.relu(tf.matmul(h_drop1, W_hidden1) + b_hidden1)\n",
    "    h_drop2 = tf.nn.dropout(h_hidden1, keep_prob2)\n",
    "\n",
    "with tf.name_scope(\"hidden_layer_2\") as scope:\n",
    "    W_hidden2, b_hidden2 = fc_weight_bias(130,70)    \n",
    "    h_hidden2 = tf.nn.relu(tf.matmul(h_drop2, W_hidden2) + b_hidden2)\n",
    "\n",
    "with tf.name_scope(\"hidden_layer_3\") as scope:\n",
    "    W_hidden3, b_hidden3 = fc_weight_bias(70,25)    \n",
    "    h_hidden3 = tf.nn.relu(tf.matmul(h_hidden2, W_hidden3) + b_hidden3)\n",
    "\n",
    "with tf.name_scope(\"output_layer\") as scope:\n",
    "    W_hidden4, b_hidden4 = fc_weight_bias(25,2)    \n",
    "    y_pred = tf.nn.softmax(tf.matmul(h_hidden3, W_hidden4) + b_hidden4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss_calculations\") as scope:\n",
    "    #cross_entropy = -tf.reduce_sum(y_true * tf.log(y_pred + 1e-8))\n",
    "    #weights_sum   = tf.add_n([tf.nn.l2_loss(variable) for variable in tf.global_variables()])\n",
    "    #mean_loss     = cross_entropy + weights_sum\n",
    "    #loss          = tf.reduce_mean(mean_loss)\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "with tf.name_scope(\"trainer\") as scope:\n",
    "    train_step    = tf.train.AdamOptimizer(0.0001).minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"accuracy_calculations\") as scope:\n",
    "    correct  = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFeed Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_feed(dataset, kp1=1.0, kp2=1.0, loss_str='loss', accuracy_str='accuracy'):\n",
    "    team1_data, team2_data = dataset.ix[:,1:137], dataset.ix[:,137:273]\n",
    "    winners = pd.get_dummies(dataset['team1Win'])\n",
    "    return {\n",
    "        x_team1: team1_data,\n",
    "        x_team2: team2_data,\n",
    "        y_true: winners,\n",
    "        loss_name: loss_str,\n",
    "        accuracy_name: accuracy_str,\n",
    "        keep_prob1: kp1,\n",
    "        keep_prob2: kp2\n",
    "    }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feed      = get_data_feed(train,      loss_str = 'loss_train',      accuracy_str = 'accuracy_train')\n",
    "validation_feed = get_data_feed(validation, loss_str = 'loss_validation', accuracy_str = 'accuracy_validation')\n",
    "test_feed       = get_data_feed(test,       loss_str = 'loss_test',       accuracy_str = 'accuracy_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(dataset, batch_size=1700): #1700 is about 1% of the entire training sets\n",
    "    #randomise before every epoch\n",
    "    dataset = dataset.take(np.random.permutation(len(dataset)))\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(dataset):\n",
    "        yield dataset[i : i + batch_size]\n",
    "        i = i + batch_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(100):    \n",
    "    for mini_batch in get_batches(train):\n",
    "        mini_batch_feed = get_data_feed(mini_batch, 0.5, 0.5)   \n",
    "        train_step.run(feed_dict = mini_batch_feed)\n",
    "    \n",
    "    #log every epoch\n",
    "    train_loss          = loss.eval(feed_dict = train_feed)\n",
    "    validation_loss     = loss.eval(feed_dict = validation_feed)\n",
    "\n",
    "    train_accuracy      = accuracy.eval(feed_dict = train_feed)\n",
    "    validation_accuracy = accuracy.eval(feed_dict = validation_feed)\n",
    "\n",
    "    print(\"epoch %d, loss: %g, train: %g, validation: %g\"% (i, train_loss, train_accuracy, validation_accuracy)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy.eval(feed_dict=test_feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
